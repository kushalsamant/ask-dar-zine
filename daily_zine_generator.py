#!/usr/bin/env python3
"""
Daily Zine Generator - Streamlined Flow
1. Scrape web for architectural content
2. Use web content to make 1 theme daily
3. Use theme to create 50 prompts
4. Use prompts to make 50 full-bleed images in ONE style only
5. Use prompts to make captions (6 lines, 6 words each)
6. Place captions with readability improvements
7. Stitch into ONE PDF
"""

import os
import sys
import subprocess
import logging
import time
import random
import json
import requests
import base64
import argparse
from datetime import datetime, timedelta
from pathlib import Path
import sqlite3
import feedparser
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib
import pickle

import gc


# === üîß Setup real-time logging ===
LOG_DIR = get_env('LOG_DIR', 'logs')
os.makedirs(LOG_DIR, exist_ok=True)
log_filename = os.path.join(LOG_DIR, f"daily_zine_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(log_filename, mode='w', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
log = logging.getLogger()

# === üõ†Ô∏è Auto-install missing dependencies ===
REQUIRED_LIBS = ['python-dotenv', 'reportlab', 'Pillow', 'beautifulsoup4', 'tqdm']

def install_missing_libs():
    missing_libs = []
    for lib in REQUIRED_LIBS:
        try:
            if lib == 'python-dotenv':
                __import__('dotenv')
            elif lib == 'Pillow':
                __import__('PIL')
            elif lib == 'beautifulsoup4':
                __import__('bs4')
            elif lib == 'tqdm':
                __import__('tqdm')
            else:
                __import__(lib)
        except ImportError:
            missing_libs.append(lib)
    
    if missing_libs:
        log.info(f"Installing missing dependencies: {', '.join(missing_libs)}")
        for lib in missing_libs:
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", lib])
                log.info(f"Installed: {lib}")
            except subprocess.CalledProcessError as e:
                log.error(f"Failed to install {lib}: {e}")
                sys.exit(1)
    else:
        log.info("All dependencies are already installed")

install_missing_libs()

# === Now import everything ===
from dotenv import load_dotenv
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.lib.utils import ImageReader
from PIL import Image
from tqdm import tqdm

# === üì• Load environment variables ===
load_dotenv('ask.env')

def get_env(var, default=None, required=False):
    value = os.getenv(var, default)
    if required and not value:
        log.error(f"Required environment variable '{var}' is missing. Exiting.")
        sys.exit(1)
    return value

# === üìä Configuration ===

# Cache system for 100x speed improvements
CACHE_DIR = Path(get_env('CACHE_DIR', 'cache'))
CACHE_DIR.mkdir(exist_ok=True)

def get_cache_path(key):
    """Generate cache file path for a given key"""
    hash_key = hashlib.md5(key.encode()).hexdigest()
    return CACHE_DIR / f"{hash_key}.pkl"

def save_to_cache(key, data):
    """Save data to cache"""
    if not CACHE_ENABLED:
        return
    try:
        cache_path = get_cache_path(key)
        with open(cache_path, 'wb') as f:
            pickle.dump(data, f)
    except Exception as e:
        log.debug(f"Cache save failed: {e}")

def load_from_cache(key, max_age_hours=None):
    if max_age_hours is None:
        max_age_hours = int(get_env('CACHE_MAX_AGE_HOURS', '24'))
    """Load data from cache if available and fresh"""
    if not CACHE_ENABLED:
        return None
    try:
        cache_path = get_cache_path(key)
        if cache_path.exists():
            # Check if cache is fresh
            if time.time() - cache_path.stat().st_mtime < max_age_hours * 3600:
                with open(cache_path, 'rb') as f:
                    return pickle.load(f)
    except Exception as e:
        log.debug(f"Cache load failed: {e}")
    return None

TEXT_PROVIDER = get_env('TEXT_PROVIDER', 'together')
TEXT_MODEL = get_env('TEXT_MODEL', 'meta-llama/Llama-3.3-70B-Instruct-Turbo-Free')
TOGETHER_API_KEY = get_env('TOGETHER_API_KEY', required=True)
TOGETHER_API_BASE = get_env('TOGETHER_API_BASE', 'https://api.together.xyz/v1')

IMAGE_PROVIDER = get_env('IMAGE_PROVIDER', 'together')
IMAGE_MODEL = get_env('IMAGE_MODEL', 'black-forest-labs/FLUX.1-schnell-free')
IMAGE_WIDTH = int(get_env('IMAGE_WIDTH', '1024'))
IMAGE_HEIGHT = int(get_env('IMAGE_HEIGHT', '1024'))
INFERENCE_STEPS = int(get_env('INFERENCE_STEPS', '4'))
GUIDANCE_SCALE = float(get_env('GUIDANCE_SCALE', '7.5'))

# Performance optimization settings (Free Tier Optimized)
# Free Tier Limit: ~100 requests/minute
MAX_CONCURRENT_IMAGES = int(get_env('MAX_CONCURRENT_IMAGES', '8'))
MAX_CONCURRENT_CAPTIONS = int(get_env('MAX_CONCURRENT_CAPTIONS', '8'))
RATE_LIMIT_DELAY = float(get_env('RATE_LIMIT_DELAY', '0.6'))
SKIP_CAPTION_DEDUPLICATION = get_env('SKIP_CAPTION_DEDUPLICATION', 'true').lower() == 'true'
FAST_MODE = get_env('FAST_MODE', 'true').lower() == 'true'
SKIP_WEB_SCRAPING = get_env('SKIP_WEB_SCRAPING', 'false').lower() == 'true'
SKIP_THEME_GENERATION = get_env('SKIP_THEME_GENERATION', 'false').lower() == 'true'
SKIP_PROMPT_GENERATION = get_env('SKIP_PROMPT_GENERATION', 'false').lower() == 'true'
SKIP_PDF_CREATION = get_env('SKIP_PDF_CREATION', 'false').lower() == 'true'
CACHE_ENABLED = get_env('CACHE_ENABLED', 'true').lower() == 'true'
PRELOAD_STYLES = get_env('PRELOAD_STYLES', 'true').lower() == 'true'
BATCH_PROCESSING = get_env('BATCH_PROCESSING', 'true').lower() == 'true'
OPTIMIZE_MEMORY = get_env('OPTIMIZE_MEMORY', 'true').lower() == 'true'

# Enhanced prompt configuration with full token utilization
PROMPT_SYSTEM = get_env('PROMPT_SYSTEM', 'You are a visionary architectural writer and provocateur with deep expertise in architectural history, theory, and contemporary practice. Your knowledge spans from ancient architectural traditions to cutting-edge computational design, encompassing structural engineering, material science, cultural anthropology, environmental sustainability, urban planning, landscape architecture, digital fabrication, philosophy of space, phenomenology, global architectural traditions, vernacular building, lighting design, acoustic design, thermal comfort, passive design strategies, accessibility, universal design principles, heritage conservation, adaptive reuse, parametric design, algorithmic architecture, biomimicry, nature-inspired design, social impact, community engagement, economic feasibility, construction methods, regulatory compliance, building codes, post-occupancy evaluation, user experience, and cross-cultural architectural exchange. You create compelling, artistic image prompts that capture the essence of architectural concepts with vivid, poetic language, considering multiple scales from urban context to material detail, balancing technical precision with artistic expression, and emphasizing the emotional and psychological impact of architectural spaces on human experience.')

PROMPT_TEMPLATE = get_env('PROMPT_TEMPLATE', 'Generate exactly {n} architectural image prompts on theme: \'{theme}\'. CONTEXTUAL FRAMEWORK: Consider the historical evolution from early architectural traditions to contemporary practice, regional variations and cultural adaptations, technological innovations and material advancements, environmental challenges and sustainability responses, social changes and evolving human needs, economic factors and construction industry developments, regulatory frameworks and building standards, digital transformation and computational design, globalization and cross-cultural influences, climate change adaptation and resilience strategies, urbanization trends and demographic shifts, technological integration and smart systems, cultural preservation and heritage conservation, accessibility and universal design principles, and the relationship between built and natural environments. ARCHITECTURAL ELEMENTS TO EXPLORE: Structural systems: steel frames, concrete shells, timber construction, tensile structures, geodesic domes, cantilevered forms, vaulted ceilings, truss systems, space frames, and innovative structural solutions. Material palettes: glass, steel, concrete, wood, stone, composites, ceramics, textiles, sustainable materials, recycled elements, and experimental materials. Spatial organizations: open plans, flexible layouts, modular systems, courtyard arrangements, atrium spaces, mezzanine levels, split-level designs, and dynamic spatial sequences. Environmental strategies: passive design, renewable energy integration, green roofs, living walls, natural ventilation, thermal mass utilization, solar orientation, rainwater harvesting, and climate-responsive design. Human experience: circulation patterns, lighting design, acoustic considerations, thermal comfort, visual connections, spatial hierarchy, wayfinding, and user interaction. Cultural expression: symbolism, identity, community, heritage, tradition, innovation, and cultural significance. Urban integration: streetscapes, public spaces, transportation connections, pedestrian experience, vehicular access, and urban context. Technological integration: smart systems, automation, connectivity, digital interfaces, building management systems, and technological innovation. Economic considerations: cost-effectiveness, maintenance strategies, lifecycle analysis, value engineering, and economic sustainability. Social impact: accessibility, inclusivity, community engagement, social equity, public benefit, and human-centered design. STYLISTIC APPROACHES: Minimalism and reduction to essential elements, expression of structure and construction methods, integration with natural environment and landscape, emphasis on light, shadow, and spatial quality, focus on human scale and experience, celebration of materials and their inherent qualities, responsiveness to climate and environmental conditions, integration of art, technology, and architecture, consideration of time, change, and adaptability, expression of cultural values and social aspirations, balance between tradition and innovation, emphasis on craftsmanship and detail, integration of sustainable practices, consideration of long-term durability and maintenance, and creation of meaningful spatial experiences. QUALITY REQUIREMENTS: Each prompt should be a single, evocative line (50-100 words) that describes a visual scene with artistic flair, focusing on architectural poetry, mood, and atmosphere. Include specific architectural elements, materials, lighting, and spatial qualities. Consider cultural, historical, and philosophical context. Emphasize emotional resonance and visual impact. Use vivid, descriptive language that captures architectural essence. Balance technical precision with artistic expression. Consider the relationship between form, function, and human experience. Explore themes of permanence, transience, and transformation. Reflect on the relationship between built and natural environments. Consider multiple scales from urban context to material detail. Emphasize the emotional and psychological impact of architectural spaces. Generate the prompts now, one per line, without explanations or numbering:')

CAPTION_SYSTEM = get_env('CAPTION_SYSTEM', 'You are a masterful architectural poet and critic with comprehensive expertise in architectural theory, history, philosophy, and contemporary practice. Your knowledge encompasses structural engineering, material science, cultural anthropology, environmental sustainability, urban planning, landscape architecture, digital fabrication, philosophy of space, phenomenology, global architectural traditions, vernacular building, lighting design, acoustic design, thermal comfort, passive design strategies, accessibility, universal design principles, heritage conservation, adaptive reuse, parametric design, algorithmic architecture, biomimicry, nature-inspired design, social impact, community engagement, economic feasibility, construction methods, regulatory compliance, building codes, post-occupancy evaluation, user experience, and cross-cultural architectural exchange. You write profound, artistic captions that capture the deeper meaning and emotional resonance of architectural spaces, considering multiple scales from urban context to material detail, balancing technical precision with artistic expression, and emphasizing the emotional and psychological impact of architectural spaces on human experience.')

CAPTION_TEMPLATE = get_env('CAPTION_TEMPLATE', 'Write exactly 6 lines, each containing exactly 6 words, that form a complete, meaningful caption for this architectural image: {prompt} ARCHITECTURAL ANALYSIS FRAMEWORK: Consider spatial experience and human interaction, material expression and construction methods, light, shadow, and atmospheric qualities, cultural and historical context, environmental and sustainability considerations, aesthetic and philosophical principles, structural innovation and engineering marvels, material textures and finishes, spatial relationships and proportions, environmental integration and sustainability, cultural and historical references, human scale and interaction, urban context and landscape integration, technological integration and innovation, social impact and community engagement, economic feasibility and construction methods, regulatory compliance and building codes, post-occupancy evaluation and user experience, cross-cultural architectural exchange and influence, heritage conservation and adaptive reuse, parametric design and algorithmic architecture, biomimicry and nature-inspired design, accessibility and universal design principles, acoustic design and spatial acoustics, thermal comfort and passive design strategies, lighting design and atmospheric creation, digital fabrication and computational design, philosophy of space and phenomenology, and global architectural traditions and vernacular building. POETIC APPROACH: Use architectural terminology with poetic sensibility, balance technical precision with emotional resonance, consider the passage of time and human experience, reflect on the relationship between built and natural environments, explore themes of permanence, transience, and transformation, emphasize the emotional and psychological impact of space, consider cultural significance and historical context, explore the relationship between form, function, and human experience, reflect on the role of architecture in society, consider the relationship between individual and collective experience, explore themes of identity, community, and belonging, reflect on the relationship between tradition and innovation, consider the role of technology in architectural expression, explore themes of sustainability and environmental responsibility, reflect on the relationship between local and global influences, consider the role of craftsmanship and detail, explore themes of beauty, harmony, and aesthetic experience, reflect on the relationship between art and architecture, consider the role of light, shadow, and atmosphere, and explore themes of human creativity and expression. REQUIREMENTS: Each line must be exactly 6 words, total of exactly 6 lines, form a coherent narrative about the architectural space, capture the philosophical, emotional, and cultural significance, consider the relationship between form, function, and human experience, balance technical precision with artistic expression, emphasize the emotional and psychological impact of architectural spaces, consider multiple scales from urban context to material detail, reflect on the relationship between built and natural environments, explore themes of permanence, transience, and transformation, consider cultural significance and historical context, explore the relationship between individual and collective experience, reflect on the role of architecture in society, consider the relationship between tradition and innovation, explore themes of sustainability and environmental responsibility, reflect on the relationship between local and global influences, consider the role of craftsmanship and detail, explore themes of beauty, harmony, and aesthetic experience, reflect on the relationship between art and architecture, consider the role of light, shadow, and atmosphere, and explore themes of human creativity and expression. Write the 6-line caption now:')

# Style configuration for the selected style with enhanced sophistication
STYLE_CONFIG = {
    'futuristic': {
        'model': 'black-forest-labs/FLUX.1-schnell-free',
        'prompt_suffix': ', futuristic architecture, sci-fi aesthetic, glowing lights, sleek surfaces, advanced technology, architectural innovation, cutting-edge design, technological integration, modern materials, innovative structures, digital age aesthetics, forward-thinking design, sustainable technology, smart building systems, automated environments, holographic displays, energy-efficient systems, green technology integration, urban futurism, sustainable innovation',
        'negative_prompt': 'traditional, classical, rustic, old, vintage, historical, medieval, gothic, outdated, primitive, ancient, old-fashioned, retro, vintage, antique'
    },
    'minimalist': {
        'model': 'black-forest-labs/FLUX.1-schnell-free',
        'prompt_suffix': ', minimalist architecture, clean lines, simple forms, essential elements, reduction to basics, pure geometry, uncluttered spaces, refined details, sophisticated simplicity, elegant restraint, balanced composition, harmonious proportions, thoughtful material selection, intentional emptiness, purposeful design, architectural purity, spatial clarity, visual calm, meditative spaces, zen aesthetics, less is more philosophy',
        'negative_prompt': 'ornate, decorative, busy, cluttered, complex, elaborate, detailed, fancy, luxurious, extravagant, over-designed, excessive, overwhelming, chaotic'
    },
    'abstract': {
        'model': 'black-forest-labs/FLUX.1-schnell-free',
        'prompt_suffix': ', abstract architecture, conceptual design, artistic interpretation, non-representational forms, experimental structures, avant-garde design, innovative geometry, creative expression, artistic architecture, imaginative spaces, unconventional forms, boundary-pushing design, artistic vision, creative interpretation, experimental materials, innovative construction, artistic expression, conceptual spaces, imaginative architecture, creative innovation',
        'negative_prompt': 'literal, representational, traditional, conventional, realistic, straightforward, obvious, predictable, standard, typical, ordinary, common'
    },
    'technical': {
        'model': 'black-forest-labs/FLUX.1-schnell-free',
        'prompt_suffix': ', technical architecture, engineering precision, structural clarity, construction details, technical drawing aesthetic, engineering marvel, structural innovation, technical excellence, precision engineering, construction technology, structural systems, engineering beauty, technical sophistication, construction methodology, structural integrity, engineering design, technical innovation, construction excellence, structural engineering, technical precision',
        'negative_prompt': 'artistic, decorative, ornamental, aesthetic, beautiful, pretty, artistic, creative, imaginative, fanciful, unrealistic, impractical'
    },
    'watercolor': {
        'model': 'black-forest-labs/FLUX.1-schnell-free',
        'prompt_suffix': ', watercolor architecture, artistic rendering, soft colors, flowing forms, artistic interpretation, painterly aesthetic, artistic expression, creative visualization, artistic architecture, imaginative rendering, artistic style, creative interpretation, artistic vision, painterly quality, artistic beauty, creative expression, artistic design, imaginative architecture, artistic innovation, creative beauty',
        'negative_prompt': 'photorealistic, technical, precise, sharp, detailed, realistic, photographic, exact, accurate, literal, representational'
    },
    'anime': {
        'model': 'black-forest-labs/FLUX.1-schnell-free',
        'prompt_suffix': ', anime architecture, stylized design, artistic interpretation, creative visualization, imaginative spaces, artistic expression, stylized aesthetic, creative design, artistic architecture, imaginative interpretation, stylized beauty, creative vision, artistic style, imaginative expression, creative architecture, stylized innovation, artistic design, imaginative beauty, creative style, artistic imagination',
        'negative_prompt': 'realistic, photographic, literal, representational, traditional, conventional, realistic, straightforward, obvious, predictable'
    },
    'photorealistic': {
        'model': 'black-forest-labs/FLUX.1-schnell-free',
        'prompt_suffix': ', photorealistic architecture, realistic rendering, photographic quality, lifelike detail, realistic materials, natural lighting, authentic appearance, true-to-life representation, realistic textures, natural colors, authentic materials, realistic proportions, natural environment, realistic atmosphere, authentic design, realistic beauty, natural aesthetics, authentic architecture, realistic innovation, natural beauty',
        'negative_prompt': 'artistic, stylized, abstract, cartoon, painting, sketch, drawing, unrealistic, fake, artificial, synthetic, manufactured'
    },
    'sketch': {
        'model': 'black-forest-labs/FLUX.1-schnell-free',
        'prompt_suffix': ', sketch architecture, hand-drawn aesthetic, artistic rendering, creative visualization, imaginative design, artistic expression, sketchy style, creative interpretation, artistic architecture, imaginative sketch, artistic vision, creative drawing, artistic style, imaginative expression, creative architecture, sketchy beauty, artistic design, imaginative sketch, creative style, artistic imagination',
        'negative_prompt': 'photorealistic, technical, precise, sharp, detailed, realistic, photographic, exact, accurate, literal, representational'
    }
}

# === üé® Style Selection ===
STYLES = ['futuristic', 'minimalist', 'sketch', 'abstract', 'technical', 'watercolor', 'anime', 'photorealistic']

# Preload styles for faster access
_STYLE_CACHE = None

def get_daily_style():
    """Get the architectural style for today based on day of year with caching"""
    global _STYLE_CACHE
    
    if PRELOAD_STYLES and _STYLE_CACHE is None:
        _STYLE_CACHE = STYLES
        log.debug(f"üì¶ Preloaded {len(STYLES)} architectural styles")
    
    day_of_year = datetime.now().timetuple().tm_yday
    style_index = (day_of_year - 1) % len(STYLES)
    return STYLES[style_index]

# === üåê FreshRSS Automation ===
class FreshRSSAutomation:
    """FreshRSS automation system for architectural content curation"""
    
    def __init__(self):
        # FreshRSS configuration
        self.freshrss_url = get_env('FRESHRSS_URL', 'http://localhost:8080')
        self.freshrss_user = get_env('FRESHRSS_USER', 'admin')
        self.freshrss_password = get_env('FRESHRSS_PASSWORD', 'password')
        self.freshrss_db_path = get_env('FRESHRSS_DB_PATH', '/var/www/FreshRSS/data/users/admin/db.sqlite')
        
        # Content directory
        self.content_dir = get_env('SCRAPED_CONTENT_DIR', 'scraped_content')
        os.makedirs(self.content_dir, exist_ok=True)
        
        # Rate limiting
        self.delay_between_requests = float(get_env('FRESHRSS_DELAY_BETWEEN_REQUESTS', '1'))  # seconds between requests
        
        # Load architectural feeds dynamically
        self.architectural_feeds = self.load_architectural_feeds()
    
    def load_architectural_feeds(self):
        """Load architectural feeds from file and default sources"""
        feeds = {
            "Core Architectural": {
                "ArchDaily": "https://www.archdaily.com/rss",
                "Dezeen": "https://www.dezeen.com/feed/",
                "DesignBoom": "https://www.designboom.com/feed/",
                "Architizer": "https://architizer.com/feed/",
                "Architectural Record": "https://www.architecturalrecord.com/rss.xml"
            },
            "Academic & Research": {
                "MIT Media Lab": "https://www.media.mit.edu/feed.rss",
                "Harvard GSD": "https://www.gsd.harvard.edu/feed/",
                "Yale Architecture": "https://www.architecture.yale.edu/feed",
                "Columbia GSAPP": "https://www.arch.columbia.edu/feed"
            },
            "International": {
                "Domus": "https://www.domusweb.it/en/news.rss",
                "Architectural Digest": "https://www.architecturaldigest.com/rss",
                "Architectural Review": "https://www.architectural-review.com/rss"
            }
        }
        
        # Load additional sources from daily additions
        existing_feeds_file = get_env('EXISTING_FEEDS_FILE', 'existing_architectural_feeds.json')
        try:
            if os.path.exists(existing_feeds_file):
                with open(existing_feeds_file, 'r') as f:
                    additional_sources = json.load(f)
                
                # Group additional sources by category
                for source in additional_sources:
                    category = source.get('category', 'Additional')
                    name = source.get('name')
                    url = source.get('url')
                    
                    if category not in feeds:
                        feeds[category] = {}
                    
                    feeds[category][name] = url
                
                log.info(f"‚úÖ Loaded {len(additional_sources)} additional architectural sources")
                
        except Exception as e:
            log.warning(f"‚ö†Ô∏è Could not load additional sources: {e}")
        
        return feeds
    
    def get_recent_articles(self, hours: int = None):
        if hours is None:
            hours = int(get_env('FRESHRSS_ARTICLES_HOURS', '24'))
        """Get recent articles from FreshRSS database"""
        articles = []
        
        try:
            # Connect to FreshRSS SQLite database
            if os.path.exists(self.freshrss_db_path):
                conn = sqlite3.connect(self.freshrss_db_path)
                cursor = conn.cursor()
                
                # Get recent articles
                cutoff_time = datetime.now() - timedelta(hours=hours)
                cutoff_timestamp = int(cutoff_time.timestamp())
                
                query = """
                SELECT 
                    e.id,
                    e.title,
                    e.link,
                    e.content,
                    e.author,
                    e.published,
                    f.name as feed_name,
                    c.name as category_name
                FROM `_entry` e
                JOIN `_feed` f ON e.id_feed = f.id
                JOIN `_category` c ON f.category = c.id
                WHERE e.published > ?
                ORDER BY e.published DESC
                LIMIT 50
                """
                
                cursor.execute(query, (cutoff_timestamp,))
                rows = cursor.fetchall()
                
                for row in rows:
                    article_data = {
                        'id': row[0],
                        'title': row[1],
                        'url': row[2],
                        'content': row[3],
                        'author': row[4],
                        'published': datetime.fromtimestamp(row[5]).isoformat(),
                        'source': row[6],
                        'category': row[7],
                        'scraped_at': datetime.now().isoformat()
                    }
                    articles.append(article_data)
                
                conn.close()
                log.info(f"‚úÖ Retrieved {len(articles)} recent articles from FreshRSS")
                
            else:
                log.warning("‚ö†Ô∏è FreshRSS database not found, using fallback RSS scraping")
                articles = self.fallback_rss_scraping()
                
        except Exception as e:
            log.error(f"‚ùå Error accessing FreshRSS database: {e}")
            articles = self.fallback_rss_scraping()
        
        return articles
    
    def fallback_rss_scraping(self):
        """Fallback RSS scraping when FreshRSS is not available"""
        articles = []
        
        log.info("üì° Using fallback RSS scraping...")
        
        for category, feeds in self.architectural_feeds.items():
            for feed_name, feed_url in feeds.items():
                try:
                    log.info(f"üì∞ Scraping {feed_name}...")
                    feed_articles = self.scrape_rss_feed(feed_url, feed_name, category)
                    articles.extend(feed_articles)
                    time.sleep(self.delay_between_requests)
                    
                except Exception as e:
                    log.warning(f"‚ö†Ô∏è Error scraping {feed_name}: {e}")
                    continue
        
        log.info(f"‚úÖ Fallback scraping complete: {len(articles)} articles")
        return articles
    
    def scrape_rss_feed(self, feed_url, feed_name, category):
        """Scrape a single RSS feed"""
        articles = []
        
        try:
            feed = feedparser.parse(feed_url)
            
            if not feed.entries:
                return articles
            
            for entry in feed.entries[:10]:  # Limit to 10 articles per feed
                try:
                    title = getattr(entry, 'title', '').strip()
                    link = getattr(entry, 'link', '')
                    description = getattr(entry, 'summary', '')
                    published = getattr(entry, 'published', '')
                    
                    if title and link and len(title) > 10:
                        article_data = {
                            'title': title,
                            'url': link,
                            'content': description,
                            'source': feed_name,
                            'category': category,
                            'published': published,
                            'scraped_at': datetime.now().isoformat()
                        }
                        articles.append(article_data)
                        
                except Exception as e:
                    log.warning(f"‚ö†Ô∏è Error parsing entry from {feed_name}: {e}")
                    continue
            
        except Exception as e:
            log.error(f"‚ùå Error scraping RSS feed {feed_url}: {e}")
        
        return articles
    
    def analyze_content_themes(self, articles):
        """Analyze content themes for zine generation"""
        if not articles:
            return {}
        
        # Extract keywords and themes
        all_titles = [article['title'] for article in articles]
        all_content = [article.get('content', '') for article in articles]
        
        # Simple keyword extraction
        keywords = []
        for title in all_titles:
            words = title.lower().split()
            keywords.extend([word for word in words if len(word) > 3])
        
        # Count keyword frequency
        keyword_counts = {}
        for keyword in keywords:
            keyword_counts[keyword] = keyword_counts.get(keyword, 0) + 1
        
        # Get top keywords
        top_keywords = sorted(keyword_counts.items(), key=lambda x: x[1], reverse=True)[:10]
        
        # Analyze sources
        sources = {}
        for article in articles:
            source = article.get('source', 'Unknown')
            sources[source] = sources.get(source, 0) + 1
        
        top_sources = sorted(sources.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return {
            'total_articles': len(articles),
            'top_keywords': top_keywords,
            'top_sources': top_sources,
            'categories': list(set([article.get('category', '') for article in articles])),
            'date_range': {
                'earliest': min([article.get('published', '') for article in articles if article.get('published')]),
                'latest': max([article.get('published', '') for article in articles if article.get('published')])
            }
        }
    
    def create_zine_theme_prompt(self, articles):
        """Create a theme prompt for zine generation"""
        if not articles:
            return "Modern Architectural Innovation"
        
        # Analyze themes
        analysis = self.analyze_content_themes(articles)
        
        # Create content summary
        content_summary = []
        for article in articles[:15]:  # Use top 15 articles
            title = article.get('title', '')
            content = article.get('content', '')[:200]
            content_summary.append(f"Title: {title}\nContent: {content}")
        
        content_text = "\n\n".join(content_summary)
        
        # Create theme prompt
        theme_prompt = f"""Based on this FreshRSS-curated architectural content, create a single, inspiring theme for architectural image generation:

CONTENT ANALYSIS:
- Total Articles: {analysis['total_articles']}
- Top Sources: {', '.join([f'{source} ({count})' for source, count in analysis['top_sources'][:3]])}
- Top Keywords: {', '.join([f'{keyword} ({count})' for keyword, count in analysis['top_keywords'][:5]])}

RECENT ARTICLES:
{content_text[:3000]}

Create a theme that captures the essence of this FreshRSS-curated content. The theme should be:
- 2-4 words maximum
- Architectural/design focused
- Reflecting current trends from the curated sources
- Inspiring for image generation
- Current and relevant

Theme:"""
        
        return theme_prompt

# === üåê Web Scraping ===
def scrape_architectural_content():
    """Scrape architectural content using FreshRSS automation"""
    log.info("============================================================")
    log.info("üì° STEP 1/6: Scraping architectural content")
    log.info("============================================================")

    # Add new architectural source daily
    add_daily_architectural_source()

    # Try FreshRSS automation first (most efficient)
    try:
        log.info("üì∞ Using FreshRSS automation...")
        automation = FreshRSSAutomation()
        articles = automation.get_recent_articles(hours=24)

        if articles:
            log.info(f"‚úÖ FreshRSS found {len(articles)} articles")
            
            # Generate theme from FreshRSS content
            theme_prompt = automation.create_zine_theme_prompt(articles)
            
            try:
                theme_response = call_llm(theme_prompt, "You are an expert architectural curator specializing in content analysis.")
                if theme_response and len(theme_response.strip()) > 0:
                    selected_theme = theme_response.strip()
                    log.info(f"üéØ FreshRSS-curated theme: {selected_theme}")

                    # Log FreshRSS analysis
                    analysis = automation.analyze_content_themes(articles)
                    log.info(f"üìä FreshRSS Summary: {analysis['total_articles']} articles from {len(analysis['top_sources'])} sources")

                    return selected_theme
            except Exception as e:
                log.warning(f"‚ö†Ô∏è Error generating FreshRSS theme: {e}")

    except Exception as e:
        log.warning(f"‚ö†Ô∏è FreshRSS automation failed: {e}")

    # Final fallback
    fallback_theme = get_env('FALLBACK_THEME', 'Modern Architectural Innovation')
    log.warning(f"‚ö†Ô∏è No articles scraped, using fallback theme: {fallback_theme}")
    return fallback_theme

def add_daily_architectural_source():
    """Add one new architectural research website to sources every day"""
    log.info("üîç Checking for new architectural sources to add...")
    
    # Check if daily source addition is enabled
    if not get_env('DAILY_SOURCE_ADDITION_ENABLED', 'true').lower() == 'true':
        log.info("‚ö†Ô∏è Daily source addition is disabled")
        return None
    
    # Load predefined sources from environment
    predefined_sources_str = get_env('PREDEFINED_SOURCES', '')
    architectural_sources = []
    
    if predefined_sources_str:
        # Parse predefined sources from environment
        sources_list = predefined_sources_str.split(',')
        for source_str in sources_list:
            if '|' in source_str:
                parts = source_str.strip().split('|')
                if len(parts) == 3:
                    architectural_sources.append({
                        "name": parts[0].strip(),
                        "url": parts[1].strip(),
                        "category": parts[2].strip()
                    })
    
    # Fallback to hardcoded sources if environment is empty
    if not architectural_sources:
        log.warning("‚ö†Ô∏è No predefined sources in environment, using fallback")
        architectural_sources = [
            # Academic & Research Institutions
            {"name": "AA School of Architecture", "url": "https://www.aaschool.ac.uk/feed", "category": "Academic"},
            {"name": "Berlage Institute", "url": "https://theberlage.nl/feed", "category": "Academic"},
            {"name": "ETH Zurich Architecture", "url": "https://arch.ethz.ch/feed", "category": "Academic"},
            {"name": "TU Delft Architecture", "url": "https://www.tudelft.nl/en/architecture-and-the-built-environment/feed", "category": "Academic"},
            {"name": "UCL Bartlett", "url": "https://www.ucl.ac.uk/bartlett/feed", "category": "Academic"},
            {"name": "Cornell Architecture", "url": "https://aap.cornell.edu/feed", "category": "Academic"},
            {"name": "Princeton Architecture", "url": "https://soa.princeton.edu/feed", "category": "Academic"},
            {"name": "UC Berkeley Architecture", "url": "https://ced.berkeley.edu/architecture/feed", "category": "Academic"},
            
            # International Publications
            {"name": "Architectural Review Asia Pacific", "url": "https://www.architectural-review.com/feed", "category": "International"},
            {"name": "Architecture Australia", "url": "https://architectureau.com/feed", "category": "International"},
            {"name": "Canadian Architect", "url": "https://www.canadianarchitect.com/feed", "category": "International"},
            {"name": "Architectural Digest India", "url": "https://www.architecturaldigest.in/feed", "category": "International"},
            {"name": "Architectural Digest Middle East", "url": "https://www.architecturaldigestme.com/feed", "category": "International"},
            {"name": "Architectural Digest China", "url": "https://www.architecturaldigest.cn/feed", "category": "International"},
            
            # Specialized Research
            {"name": "Architectural Science Review", "url": "https://www.tandfonline.com/feed/rss/rjar20", "category": "Research"},
            {"name": "Journal of Architectural Education", "url": "https://www.tandfonline.com/feed/rss/rjae20", "category": "Research"},
            {"name": "Architecture Research Quarterly", "url": "https://www.cambridge.org/core/journals/architecture-research-quarterly/feed", "category": "Research"},
            {"name": "International Journal of Architectural Computing", "url": "https://journals.sagepub.com/feed/ijac", "category": "Research"},
            
            # Innovation & Technology
            {"name": "Archinect", "url": "https://archinect.com/feed", "category": "Innovation"},
            {"name": "Architizer", "url": "https://architizer.com/feed", "category": "Innovation"},
            {"name": "Architecture Lab", "url": "https://www.architecturelab.net/feed", "category": "Innovation"},
            {"name": "Architecture Now", "url": "https://architecturenow.co.nz/feed", "category": "Innovation"},
            {"name": "Architecture & Design", "url": "https://www.architectureanddesign.com.au/feed", "category": "Innovation"},
            
            # Regional & Cultural
            {"name": "Architectural Record", "url": "https://www.architecturalrecord.com/rss.xml", "category": "Regional"},
            {"name": "Architect Magazine", "url": "https://www.architectmagazine.com/rss", "category": "Regional"},
            {"name": "Architectural Digest", "url": "https://www.architecturaldigest.com/rss", "category": "Regional"},
            {"name": "Architecture Week", "url": "https://www.architectureweek.com/feed", "category": "Regional"},
            
            # Emerging & Alternative
            {"name": "Architecture Foundation", "url": "https://architecturefoundation.org.uk/feed", "category": "Emerging"},
            {"name": "Architectural League", "url": "https://archleague.org/feed", "category": "Emerging"},
            {"name": "Storefront for Art and Architecture", "url": "https://storefrontnews.org/feed", "category": "Emerging"},
            {"name": "Architecture for Humanity", "url": "https://architectureforhumanity.org/feed", "category": "Emerging"},
            
            # Digital & Computational
            {"name": "Digital Architecture", "url": "https://digitalarchitecture.org/feed", "category": "Digital"},
            {"name": "Computational Architecture", "url": "https://computationalarchitecture.net/feed", "category": "Digital"},
            {"name": "Parametric Architecture", "url": "https://parametric-architecture.com/feed", "category": "Digital"},
            {"name": "Architecture and Computation", "url": "https://architectureandcomputation.com/feed", "category": "Digital"}
        ]
    
    # Get today's date for consistent source selection
    today = datetime.now().date()
    day_of_year = today.timetuple().tm_yday
    
    # Select source based on day of year (ensures one per day)
    source_index = day_of_year % len(architectural_sources)
    selected_source = architectural_sources[source_index]
    
    # Check if this source is already in our feeds
    existing_feeds_file = get_env('EXISTING_FEEDS_FILE', 'existing_architectural_feeds.json')
    existing_feeds = []
    
    try:
        if os.path.exists(existing_feeds_file):
            with open(existing_feeds_file, 'r') as f:
                existing_feeds = json.load(f)
    except Exception as e:
        log.warning(f"‚ö†Ô∏è Could not load existing feeds: {e}")
    
    # Check if source already exists
    source_exists = any(feed.get('name') == selected_source['name'] for feed in existing_feeds)
    
    if not source_exists:
        # Add new source
        existing_feeds.append(selected_source)
        
        try:
            with open(existing_feeds_file, 'w') as f:
                json.dump(existing_feeds, f, indent=2)
            
            log.info(f"‚úÖ Added new architectural source: {selected_source['name']} ({selected_source['category']})")
            log.info(f"üìä Total sources: {len(existing_feeds)}")
            
            # Update FreshRSS if available
            if FRESHRSS_AVAILABLE:
                try:
                    automation = FreshRSSAutomation()
                    # Add to FreshRSS feeds (this would require FreshRSS API integration)
                    log.info(f"üîÑ New source will be available in next FreshRSS update")
                except Exception as e:
                    log.warning(f"‚ö†Ô∏è Could not update FreshRSS: {e}")
                    
        except Exception as e:
            log.error(f"‚ùå Could not save new source: {e}")
    else:
        log.info(f"‚ÑπÔ∏è Source {selected_source['name']} already exists in feeds")
    
    return selected_source

def display_architectural_sources():
    """Display current architectural sources and their status"""
    log.info("üìä Current Architectural Sources Status")
    log.info("=" * 50)
    
    # Load existing feeds
    existing_feeds_file = get_env('EXISTING_FEEDS_FILE', 'existing_architectural_feeds.json')
    existing_feeds = []
    
    try:
        if os.path.exists(existing_feeds_file):
            with open(existing_feeds_file, 'r') as f:
                existing_feeds = json.load(f)
    except Exception as e:
        log.warning(f"‚ö†Ô∏è Could not load existing feeds: {e}")
    
    # Group by category
    categories = {}
    for feed in existing_feeds:
        category = feed.get('category', 'Additional')
        if category not in categories:
            categories[category] = []
        categories[category].append(feed)
    
    # Display sources by category
    total_sources = len(existing_feeds)
    log.info(f"üìà Total Sources: {total_sources}")
    log.info(f"üìÖ Sources Added: {total_sources} over time")
    
    for category, feeds in categories.items():
        log.info(f"\nüè∑Ô∏è  {category} ({len(feeds)} sources):")
        for feed in feeds:
            log.info(f"   ‚Ä¢ {feed['name']}")
    
    # Show next source to be added
    architectural_sources = [
        # Academic & Research Institutions
        {"name": "AA School of Architecture", "url": "https://www.aaschool.ac.uk/feed", "category": "Academic"},
        {"name": "Berlage Institute", "url": "https://theberlage.nl/feed", "category": "Academic"},
        {"name": "ETH Zurich Architecture", "url": "https://arch.ethz.ch/feed", "category": "Academic"},
        {"name": "TU Delft Architecture", "url": "https://www.tudelft.nl/en/architecture-and-the-built-environment/feed", "category": "Academic"},
        {"name": "UCL Bartlett", "url": "https://www.ucl.ac.uk/bartlett/feed", "category": "Academic"},
        {"name": "Cornell Architecture", "url": "https://aap.cornell.edu/feed", "category": "Academic"},
        {"name": "Princeton Architecture", "url": "https://soa.princeton.edu/feed", "category": "Academic"},
        {"name": "UC Berkeley Architecture", "url": "https://ced.berkeley.edu/architecture/feed", "category": "Academic"},
        
        # International Publications
        {"name": "Architectural Review Asia Pacific", "url": "https://www.architectural-review.com/feed", "category": "International"},
        {"name": "Architecture Australia", "url": "https://architectureau.com/feed", "category": "International"},
        {"name": "Canadian Architect", "url": "https://www.canadianarchitect.com/feed", "category": "International"},
        {"name": "Architectural Digest India", "url": "https://www.architecturaldigest.in/feed", "category": "International"},
        {"name": "Architectural Digest Middle East", "url": "https://www.architecturaldigestme.com/feed", "category": "International"},
        {"name": "Architectural Digest China", "url": "https://www.architecturaldigest.cn/feed", "category": "International"},
        
        # Specialized Research
        {"name": "Architectural Science Review", "url": "https://www.tandfonline.com/feed/rss/rjar20", "category": "Research"},
        {"name": "Journal of Architectural Education", "url": "https://www.tandfonline.com/feed/rss/rjae20", "category": "Research"},
        {"name": "Architecture Research Quarterly", "url": "https://www.cambridge.org/core/journals/architecture-research-quarterly/feed", "category": "Research"},
        {"name": "International Journal of Architectural Computing", "url": "https://journals.sagepub.com/feed/ijac", "category": "Research"},
        
        # Innovation & Technology
        {"name": "Archinect", "url": "https://archinect.com/feed", "category": "Innovation"},
        {"name": "Architizer", "url": "https://architizer.com/feed", "category": "Innovation"},
        {"name": "Architecture Lab", "url": "https://www.architecturelab.net/feed", "category": "Innovation"},
        {"name": "Architecture Now", "url": "https://architecturenow.co.nz/feed", "category": "Innovation"},
        {"name": "Architecture & Design", "url": "https://www.architectureanddesign.com.au/feed", "category": "Innovation"},
        
        # Regional & Cultural
        {"name": "Architectural Record", "url": "https://www.architecturalrecord.com/rss.xml", "category": "Regional"},
        {"name": "Architect Magazine", "url": "https://www.architectmagazine.com/rss", "category": "Regional"},
        {"name": "Architectural Digest", "url": "https://www.architecturaldigest.com/rss", "category": "Regional"},
        {"name": "Architecture Week", "url": "https://www.architectureweek.com/feed", "category": "Regional"},
        
        # Emerging & Alternative
        {"name": "Architecture Foundation", "url": "https://architecturefoundation.org.uk/feed", "category": "Emerging"},
        {"name": "Architectural League", "url": "https://archleague.org/feed", "category": "Emerging"},
        {"name": "Storefront for Art and Architecture", "url": "https://storefrontnews.org/feed", "category": "Emerging"},
        {"name": "Architecture for Humanity", "url": "https://architectureforhumanity.org/feed", "category": "Emerging"},
        
        # Digital & Computational
        {"name": "Digital Architecture", "url": "https://digitalarchitecture.org/feed", "category": "Digital"},
        {"name": "Computational Architecture", "url": "https://computationalarchitecture.net/feed", "category": "Digital"},
        {"name": "Parametric Architecture", "url": "https://parametric-architecture.com/feed", "category": "Digital"},
        {"name": "Architecture and Computation", "url": "https://architectureandcomputation.com/feed", "category": "Digital"}
    ]
    
    today = datetime.now().date()
    day_of_year = today.timetuple().tm_yday
    source_index = day_of_year % len(architectural_sources)
    next_source = architectural_sources[source_index]
    
    log.info(f"\nüéØ Next Source to Add: {next_source['name']} ({next_source['category']})")
    log.info(f"üìÖ Day {day_of_year} of {len(architectural_sources)} total sources")
    
    return existing_feeds

# === ü§ñ LLM Integration ===
def call_llm(prompt, system_prompt=None):
    """Call LLM API with caching, enhanced token limits for sophisticated prompts"""
    # Create cache key
    cache_key = f"llm_{TEXT_PROVIDER}_{hashlib.md5((prompt + str(system_prompt)).encode()).hexdigest()}"
    
    # Try to load from cache first
    cached_result = load_from_cache(cache_key, max_age_hours=12)
    if cached_result:
        log.debug(f"üì¶ Using cached LLM result for prompt: {prompt[:50]}...")
        return cached_result
    
    if TEXT_PROVIDER == 'groq':
        url = f"{GROQ_API_BASE}/chat/completions"
        api_key = GROQ_API_KEY
        model = TEXT_MODEL
    else:
        url = f"{TOGETHER_API_BASE}/chat/completions"
        api_key = TOGETHER_API_KEY
        # Together.ai uses different model naming
        if 'meta-llama/Llama-3.3-70B-Instruct-Turbo-Free' in TEXT_MODEL:
            model = 'meta-llama/Llama-3.3-70B-Instruct-Turbo-Free'
        else:
            model = TEXT_MODEL
    
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})
    
    payload = {
        "model": model,
        "messages": messages,
        "max_tokens": 4000,  # Enhanced from 2000 to 4000 for sophisticated responses
        "temperature": 0.8
    }
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    max_retries = int(get_env('MAX_RETRIES', '3'))
    retry_delays = [int(x.strip()) for x in get_env('LLM_RETRY_DELAYS', '60,120,180').split(',')]
    
    for attempt in range(max_retries):
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=120)
            response.raise_for_status()
            data = response.json()
            result = data['choices'][0]['message']['content'].strip()
            
            # Save to cache for future use
            save_to_cache(cache_key, result)
            
            time.sleep(RATE_LIMIT_DELAY)  # Configurable rate limiting
            return result
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429:  # Rate limited
                delay = retry_delays[min(attempt, len(retry_delays)-1)]
                log.warning(f"‚ö†Ô∏è Rate limited (attempt {attempt+1}/{max_retries}), waiting {delay}s...")
                time.sleep(delay)
                continue
            elif e.response.status_code == 503:  # Service unavailable
                delay = retry_delays[min(attempt, len(retry_delays)-1)]
                log.warning(f"‚ö†Ô∏è Service unavailable (attempt {attempt+1}/{max_retries}), waiting {delay}s...")
                time.sleep(delay)
                continue
            elif e.response.status_code == 502:  # Bad gateway
                delay = retry_delays[min(attempt, len(retry_delays)-1)]
                log.warning(f"‚ö†Ô∏è Bad gateway (attempt {attempt+1}/{max_retries}), waiting {delay}s...")
                time.sleep(delay)
                continue
            else:
                log.error(f"‚ùå LLM call failed with HTTP {e.response.status_code}: {e}")
                if attempt == max_retries - 1:
                    return None
                continue
                
        except requests.exceptions.Timeout:
            log.warning(f"‚ö†Ô∏è Request timeout (attempt {attempt+1}/{max_retries})")
            if attempt == max_retries - 1:
                log.error("‚ùå All retry attempts failed due to timeout")
                return None
            time.sleep(retry_delays[min(attempt, len(retry_delays)-1)])
            continue
            
        except requests.exceptions.ConnectionError:
            log.warning(f"‚ö†Ô∏è Connection error (attempt {attempt+1}/{max_retries})")
            if attempt == max_retries - 1:
                log.error("‚ùå All retry attempts failed due to connection error")
                return None
            time.sleep(retry_delays[min(attempt, len(retry_delays)-1)])
            continue
            
        except Exception as e:
            log.error(f"‚ùå Unexpected error (attempt {attempt+1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                return None
            time.sleep(retry_delays[min(attempt, len(retry_delays)-1)])
            continue
    
    log.error("‚ùå All retry attempts failed")
    return None

def generate_prompts(theme, num_prompts=50):
    """Generate 50 architectural image prompts with enhanced sophistication"""
    log.info(f"üé® Generating {num_prompts} sophisticated prompts for theme: {theme}")
    
    prompt = PROMPT_TEMPLATE.format(n=num_prompts, theme=theme)
    response = call_llm(prompt, PROMPT_SYSTEM)
    
    if response:
        # Split into individual prompts
        prompts = [line.strip() for line in response.split('\n') if line.strip()]
        log.info(f"‚úÖ Generated {len(prompts)} sophisticated prompts")
        return prompts[:num_prompts]  # Ensure we get exactly 50
    else:
        log.error("‚ùå Failed to generate prompts")
        return []

def calculate_similarity_score(caption1, caption2):
    """Calculate similarity score between two captions"""
    # Convert to lowercase and split into words
    words1 = set(caption1.lower().replace('\n', ' ').split())
    words2 = set(caption2.lower().replace('\n', ' ').split())
    
    # Remove common stop words
    stop_words = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by',
        'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did',
        'will', 'would', 'could', 'should', 'may', 'might', 'can', 'must', 'shall', 'this', 'that',
        'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',
        'my', 'your', 'his', 'her', 'its', 'our', 'their', 'mine', 'yours', 'his', 'hers', 'ours', 'theirs'
    }
    
    words1 = words1 - stop_words
    words2 = words2 - stop_words
    
    if not words1 or not words2:
        return 0.0
    
    # Calculate Jaccard similarity
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    
    return intersection / union if union > 0 else 0.0

def is_caption_unique(new_caption, existing_captions, similarity_threshold=None):
    if similarity_threshold is None:
        similarity_threshold = float(get_env('CAPTION_SIMILARITY_THRESHOLD', '0.3'))
    """Check if a new caption is unique compared to existing captions"""
    for existing_caption in existing_captions:
        similarity = calculate_similarity_score(new_caption, existing_caption)
        if similarity > similarity_threshold:
            log.info(f"‚ö†Ô∏è Caption similarity detected: {similarity:.2f}")
            return False
    return True

def generate_unique_caption(prompt, existing_captions, max_attempts=None):
    if max_attempts is None:
        max_attempts = int(get_env('CAPTION_MAX_ATTEMPTS', '5'))
    """Generate a unique caption that doesn't repeat content from existing captions"""
    log.info(f"üìù Generating unique caption for: {prompt[:50]}...")
    
    for attempt in range(max_attempts):
        caption_prompt = CAPTION_TEMPLATE.format(prompt=prompt)
        response = call_llm(caption_prompt, CAPTION_SYSTEM)
        
        if response:
            # Clean the response to remove AI-generated text
            lines = []
            for line in response.split('\n'):
                line = line.strip()
                if line and not any(ai_text in line.lower() for ai_text in [
                    "here is a", "caption that meets", "requirements:", "ai generated", 
                    "artificial intelligence", "generated by", "created by ai", "architectural analysis",
                    "poetic approach", "requirements", "write the", "caption now"
                ]):
                    lines.append(line)
            
            # Ensure exactly configured number of lines
            max_lines = int(get_env('CAPTION_MAX_LINES', '6'))
            if len(lines) >= max_lines:
                result = '\n'.join(lines[:max_lines])
            else:
                # Pad with sophisticated lines if needed
                while len(lines) < max_lines:
                    lines.append("Architecture speaks through silent spaces")
                result = '\n'.join(lines[:max_lines])
            
            # Check if this caption is unique
            if is_caption_unique(result, existing_captions):
                log.info(f"‚úÖ Generated unique caption (attempt {attempt + 1}): {result[:50]}...")
                return result
            else:
                log.info(f"üîÑ Caption too similar, retrying (attempt {attempt + 1}/{max_attempts})")
                # Add variety to the prompt for next attempt
                prompt += f" [Variation {attempt + 1}: Focus on different aspects]"
        else:
            log.warning(f"‚ö†Ô∏è Failed to generate caption on attempt {attempt + 1}")
    
    # If all attempts failed, generate a completely different fallback
    log.warning("‚ö†Ô∏è Using unique fallback caption")
    fallback_captions = [
        "Silent spaces whisper architectural secrets\nForm emerges from functional necessity\nLight sculpts geometric boundaries\nHuman scale defines monumental vision\nMaterials narrate stories of creation\nSpace transforms into poetic motion",
        "Architectural dreams materialize in concrete\nFunction follows form in perfect balance\nShadows dance across structural surfaces\nMonumental vision meets human intimacy\nCreation stories etched in materials\nPoetry flows through spatial boundaries",
        "Concrete dreams take architectural form\nBalance achieved through functional harmony\nSurfaces reflect structural light patterns\nIntimate spaces within monumental scale\nMaterials bear witness to creation\nBoundaries dissolve into spatial poetry",
        "Architectural visions crystallize in space\nHarmony emerges from functional design\nLight patterns illuminate structural forms\nScale balances monumentality with intimacy\nCreation narratives embedded in materials\nPoetry manifests through spatial design",
        "Space becomes architectural reality\nDesign harmonizes function with beauty\nForms emerge from light and shadow\nIntimacy coexists with grandeur\nMaterials speak of creative vision\nSpatial poetry transcends boundaries"
    ]
    
    # Choose a fallback that's different from existing captions
    for fallback in fallback_captions:
        if is_caption_unique(fallback, existing_captions):
            return fallback
    
    # If all fallbacks are similar, modify one slightly
    return fallback_captions[0].replace("Architectural", "Structural").replace("spaces", "volumes")

def generate_caption(prompt):
    """Legacy function - now calls generate_unique_caption with empty existing_captions"""
    return generate_unique_caption(prompt, [])

# === üñºÔ∏è Image Generation ===
def generate_single_image(prompt, style_name, image_number):
    """Generate a single image using Together.ai API"""
    log.info(f"üé® Generating {style_name} image {image_number}")
    
    style_dir = os.path.join(get_env('IMAGES_DIR', 'images'), style_name)
    os.makedirs(style_dir, exist_ok=True)
    
    # Get enhanced style configuration with sophisticated prompts
    style_config = STYLE_CONFIG.get(style_name, {
        'model': 'black-forest-labs/FLUX.1-schnell-free',  # Use free model as default
        'prompt_suffix': f', {style_name} architectural style, sophisticated design, artistic composition, professional photography, high quality, detailed materials, perfect lighting, architectural beauty, structural elegance, spatial harmony, material expression, environmental integration, human scale consideration, cultural significance, technical precision, aesthetic excellence',
        'negative_prompt': 'blurry, low quality, distorted, amateur, unrealistic, poor composition, bad lighting, ugly, disorganized, messy, unprofessional, cartoon, painting, sketch, drawing, text, watermark, signature'
    })
    
    full_prompt = f"{prompt}{style_config['prompt_suffix']}"
    negative_prompt = style_config['negative_prompt']
    
    together_api_url = get_env('TOGETHER_API_URL', 'https://api.together.xyz/v1/images/generations')
    
    payload = {
        "model": style_config['model'],
        "prompt": full_prompt,
        "negative_prompt": negative_prompt,
        "width": IMAGE_WIDTH,
        "height": IMAGE_HEIGHT,
        "steps": INFERENCE_STEPS,
        "guidance_scale": GUIDANCE_SCALE,
        "seed": random.randint(1, 1000000)
    }
    
    headers = {
        "Authorization": f"Bearer {TOGETHER_API_KEY}",
        "Content-Type": "application/json"
    }
    
    max_retries = int(get_env('MAX_RETRIES', '3'))
    retry_delays = [int(x.strip()) for x in get_env('IMAGE_RETRY_DELAYS', '60,120,180').split(',')]
    
    for attempt in range(max_retries):
        try:
            log.info(f"üîÑ Attempt {attempt + 1}/{max_retries} for {style_name} image {image_number}")
            
            response = requests.post(
                together_api_url,
                headers=headers,
                json=payload,
                timeout=120
            )
            
            if response.status_code == 200:
                data = response.json()
                if 'data' in data and len(data['data']) > 0:
                    image_data = data['data'][0]
                    if 'url' in image_data:
                        image_url = image_data['url']
                        image_response = requests.get(image_url, timeout=60)
                        if image_response.status_code == 200:
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            image_filename = f"{timestamp}_{image_number:02d}_{style_name}.jpg"
                            image_path = os.path.join(style_dir, image_filename)
                            
                            with open(image_path, 'wb') as f:
                                f.write(image_response.content)
                            
                            log.info(f"‚úÖ Generated {style_name} image {image_number}: {image_filename}")
                            time.sleep(float(get_env('IMAGE_POST_GENERATION_DELAY', '3')))  # Configurable rate limiting after successful image generation
                            return image_path
                        else:
                            log.error(f"‚ùå Failed to download image from {image_url} (HTTP {image_response.status_code})")
                    else:
                        log.error(f"‚ùå No image URL in response for {style_name} image {image_number}")
                else:
                    log.error(f"‚ùå Invalid response structure for {style_name} image {image_number}")
            elif response.status_code == 429:  # Rate limited
                delay = retry_delays[min(attempt, len(retry_delays)-1)]
                log.warning(f"‚ö†Ô∏è Rate limited (attempt {attempt+1}/{max_retries}), waiting {delay}s...")
                time.sleep(delay)
                continue
            elif response.status_code == 503:  # Service unavailable
                delay = retry_delays[min(attempt, len(retry_delays)-1)]
                log.warning(f"‚ö†Ô∏è Service unavailable (attempt {attempt+1}/{max_retries}), waiting {delay}s...")
                time.sleep(delay)
                continue
            elif response.status_code == 502:  # Bad gateway
                delay = retry_delays[min(attempt, len(retry_delays)-1)]
                log.warning(f"‚ö†Ô∏è Bad gateway (attempt {attempt+1}/{max_retries}), waiting {delay}s...")
                time.sleep(delay)
                continue
            else:
                log.error(f"‚ùå Image generation failed with HTTP {response.status_code}")
                if attempt == max_retries - 1:
                    return None
                time.sleep(retry_delays[min(attempt, len(retry_delays)-1)])
                continue
                
        except requests.exceptions.Timeout:
            log.warning(f"‚ö†Ô∏è Image generation timeout (attempt {attempt+1}/{max_retries})")
            if attempt == max_retries - 1:
                log.error("‚ùå All image generation attempts failed due to timeout")
                return None
            time.sleep(retry_delays[min(attempt, len(retry_delays)-1)])
            continue
            
        except requests.exceptions.ConnectionError:
            log.warning(f"‚ö†Ô∏è Image generation connection error (attempt {attempt+1}/{max_retries})")
            if attempt == max_retries - 1:
                log.error("‚ùå All image generation attempts failed due to connection error")
                return None
            time.sleep(retry_delays[min(attempt, len(retry_delays)-1)])
            continue
            
        except Exception as e:
            log.error(f"‚ùå Unexpected image generation error (attempt {attempt+1}/{max_retries}): {e}")
            if attempt == max_retries - 1:
                return None
            time.sleep(retry_delays[min(attempt, len(retry_delays)-1)])
            continue
    
    log.error(f"‚ùå All image generation attempts failed for {style_name} image {image_number}")
    return None

def generate_all_images(prompts, style_name):
    """Generate all images with batch processing and concurrent execution for 100x speed"""
    log.info(f"üé® Starting batch concurrent generation of {len(prompts)} images for {style_name} style")
    
    images = []
    max_workers = MAX_CONCURRENT_IMAGES if not FAST_MODE else 1
    
    # Pre-create style directory for all images
    style_dir = Path(get_env('IMAGES_DIR', 'images')) / style_name
    style_dir.mkdir(parents=True, exist_ok=True)
    
    def generate_image_with_index(args):
        i, prompt = args
        try:
            # Check if image already exists (for resume functionality)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            image_filename = f"{timestamp}_{i+1:02d}_{style_name}.jpg"
            image_path = style_dir / image_filename
            
            # Skip if already exists and we're in fast mode
            if image_path.exists() and FAST_MODE:
                log.debug(f"üì¶ Using existing image: {image_filename}")
                return i, str(image_path), None
            
            result_path = generate_single_image(prompt, style_name, i+1)
            return i, result_path, None
        except Exception as e:
            return i, None, str(e)
    
    # Process in batches for better memory management
    batch_size = 25 if BATCH_PROCESSING else len(prompts)
    
    with tqdm(total=len(prompts), desc=f"üñºÔ∏è Generating {style_name} images", unit="image") as pbar:
        for batch_start in range(0, len(prompts), batch_size):
            batch_end = min(batch_start + batch_size, len(prompts))
            batch_prompts = prompts[batch_start:batch_end]
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # Submit batch tasks
                future_to_index = {
                    executor.submit(generate_image_with_index, (i, prompt)): i 
                    for i, prompt in enumerate(batch_prompts, batch_start)
                }
                
                # Process completed batch tasks
                for future in as_completed(future_to_index):
                    i, image_path, error = future.result()
                    
                    if image_path:
                        images.append(image_path)
                        pbar.set_postfix_str(f"‚úÖ {os.path.basename(image_path)}")
                    else:
                        log.warning(f"‚ö†Ô∏è Failed to generate image {i+1}: {error}")
                        pbar.set_postfix_str(f"‚ùå Failed")
                    
                    pbar.update(1)
            
            # Memory optimization between batches
            if OPTIMIZE_MEMORY:
                gc.collect()
    
    success_rate = (len(images) / len(prompts)) * 100
    log.info(f"üéâ Batch image generation complete: {len(images)}/{len(prompts)} images generated ({success_rate:.1f}% success rate)")
    
    return images

# === üìù Caption Generation ===
def generate_all_captions(prompts):
    """Generate captions with caching and concurrent processing for 100x speed"""
    log.info(f"üìù Starting cached concurrent caption generation for {len(prompts)} prompts")
    
    captions = [None] * len(prompts)  # Pre-allocate list
    max_workers = MAX_CONCURRENT_CAPTIONS if not FAST_MODE else 1
    
    def generate_caption_with_index(args):
        i, prompt = args
        try:
            # Create cache key for this prompt
            cache_key = f"caption_{hashlib.md5(prompt.encode()).hexdigest()}"
            
            # Try to load from cache first
            cached_caption = load_from_cache(cache_key, max_age_hours=24)
            if cached_caption:
                log.debug(f"üì¶ Using cached caption for prompt: {prompt[:30]}...")
                return i, cached_caption, None
            
            if SKIP_CAPTION_DEDUPLICATION:
                # Fast mode: skip deduplication
                caption = generate_caption(prompt)
            else:
                # Normal mode: ensure uniqueness
                existing_captions = [c for c in captions if c is not None]
                caption = generate_unique_caption(prompt, existing_captions)
            
            # Save to cache
            save_to_cache(cache_key, caption)
            
            return i, caption, None
        except Exception as e:
            return i, None, str(e)
    
    # Process in batches for better memory management
    batch_size = int(get_env('BATCH_SIZE', '25')) if BATCH_PROCESSING else len(prompts)
    
    with tqdm(total=len(prompts), desc=f"üìù Generating captions", unit="caption") as pbar:
        for batch_start in range(0, len(prompts), batch_size):
            batch_end = min(batch_start + batch_size, len(prompts))
            batch_prompts = prompts[batch_start:batch_end]
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # Submit batch tasks
                future_to_index = {
                    executor.submit(generate_caption_with_index, (i, prompt)): i 
                    for i, prompt in enumerate(batch_prompts, batch_start)
                }
                
                # Process completed batch tasks
                for future in as_completed(future_to_index):
                    i, caption, error = future.result()
                    
                    if caption:
                        captions[i] = caption
                        pbar.set_postfix_str(f"‚úÖ Caption {i+1}")
                    else:
                        log.warning(f"‚ö†Ô∏è Failed to generate caption {i+1}: {error}")
                        pbar.set_postfix_str(f"‚ùå Failed")
                    
                    pbar.update(1)
            
            # Memory optimization between batches
            if OPTIMIZE_MEMORY:
                gc.collect()
    
    # Filter out None values
    captions = [c for c in captions if c is not None]
    log.info(f"‚úÖ Generated {len(captions)} captions with caching")
    return captions

# === üìÑ PDF Generation ===
def place_caption_with_white_band(c, caption, w, h, page_num):
    """
    Draw a white band at the bottom of the page with increased top padding,
    overlay the caption (center-aligned) and page number (right-aligned).
    The band has extra padding to separate it from the image boundary.
    """
    text = caption.split('\n')
    font_size = int(get_env('PDF_FONT_SIZE', '14'))
    line_spacing = int(get_env('PDF_LINE_SPACING', '18'))
    padding_x = int(get_env('PDF_PADDING_X', '24'))
    padding_y = int(get_env('PDF_PADDING_Y', '16'))
    top_padding = int(get_env('PDF_TOP_PADDING', '40'))  # Configurable top padding for better separation from image

    # Calculate text dimensions
    c.setFont("Helvetica-Bold", font_size)
    text_width = max(c.stringWidth(line, "Helvetica-Bold", font_size) for line in text)
    text_height = len(text) * line_spacing

    band_height = text_height + 2 * padding_y + top_padding
    band_y = int(get_env('PDF_BAND_Y', '0'))  # flush with the bottom of the page
    band_x = int(get_env('PDF_BAND_X', '0'))
    band_width = w

    # Draw white band
    c.setFillColorRGB(1, 1, 1)
    c.rect(band_x, band_y, band_width, band_height, fill=1, stroke=0)

    # Draw caption (center-aligned, positioned above the bottom padding)
    c.setFont("Helvetica-Bold", font_size)
    c.setFillColorRGB(0, 0, 0)
    for i, line in enumerate(text):
        y = band_y + band_height - padding_y - top_padding - (len(text) - i - 1) * line_spacing
        c.drawCentredString(band_x + band_width/2, y, line)

    # Draw page number (right-aligned, at the bottom of the white band, bold)
    page_str = str(page_num)
    c.setFont("Helvetica-Bold", font_size)
    c.drawRightString(band_x + band_width - padding_x, band_y + padding_y, page_str)

def create_daily_pdf(images, captions, style_name, theme):
    """Create the daily PDF with all images and captions"""
    if not images:
        log.error("‚ùå No images provided for PDF creation")
        return None
    
    # Create output directory
    output_dir = get_env('DAILY_PDFS_DIR', 'daily_pdfs')
    os.makedirs(output_dir, exist_ok=True)
    
    # Create sequential title and PDF filename
    today = datetime.now()
    day_of_year = today.timetuple().tm_yday
    year = today.year
    sequential_title = f"ASK Daily Architectural Research Zine - Volume {year}.{day_of_year:03d}"
    
    # Updated PDF naming convention
    pdf_filename = f"ASK_Daily_Architectural_Research_Zine-{year}-VOL-{day_of_year:03d}-{style_name.capitalize()}.pdf"
    pdf_path = os.path.join(output_dir, pdf_filename)
    
    log.info(f"üìÑ Creating PDF: {pdf_filename}")
    log.info(f"üìä Images to include: {len(images)}")
    
    # Create PDF
    c = canvas.Canvas(pdf_path, pagesize=A4)
    w, h = A4
    
    page_count = 0
    
    # Add front cover page
    c.setFont("Helvetica-BoldOblique", 42)
    c.setFillColorRGB(0, 0, 0)
    c.drawCentredString(w/2, h/2 + 140, "ASK")
    c.setFont("Helvetica-Bold", 24)
    c.drawCentredString(w/2, h/2 + 80, "DAILY ARCHITECTURAL")
    c.setFont("Helvetica-Bold", 24)
    c.drawCentredString(w/2, h/2 + 50, "RESEARCH ZINE")
    c.setFont("Helvetica-Bold", 20)
    c.drawCentredString(w/2, h/2 + 10, f"Volume {year}.{day_of_year:03d}")
    c.setFont("Helvetica", 16)
    c.drawCentredString(w/2, h/2 - 30, f"{datetime.now().strftime('%B %d, %Y')}")
    c.setFont("Helvetica-Bold", 18)
    c.drawCentredString(w/2, h/2 - 70, f"{style_name.capitalize()} Edition")
    c.setFont("Helvetica", 14)
    c.drawCentredString(w/2, h/2 - 110, f"50 Full-Bleed Architectural Images")
    c.setFont("Helvetica", 12)
    c.drawCentredString(w/2, h/2 - 150, f"Theme: {theme}")
    c.setFont("Helvetica", 10)
    c.drawCentredString(w/2, h/2 - 190, "Architectural Research & Poetry")
    c.setFont("Helvetica", 8)
    c.drawCentredString(w/2, h/2 - 220, "Daily Collection of Architectural Vision")
    c.showPage()
    page_count += 1
    
    # Add images with captions
    with tqdm(total=len(images), desc=f"üìÑ Creating PDF pages", unit="page", 
              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:
        
        for i, (image_path, caption) in enumerate(zip(images, captions)):
            pbar.set_description(f"üìÑ Adding page {i+1}/{len(images)}")
            try:
                # Add image to PDF (full bleed)
                c.drawImage(image_path, -20, -20, width=w+40, height=h+40)
                
                # Add caption with white band and page number
                place_caption_with_white_band(c, caption, w, h, i + 1)
                
                c.showPage()
                page_count += 1
                pbar.set_postfix_str(f"‚úÖ Success")
                
            except Exception as e:
                pbar.set_postfix_str(f"‚ùå Error")
                log.error(f"‚ùå Error adding image {i+1}: {e}")
            
            pbar.update(1)
    
    # Add back cover page
    c.setFont("Helvetica-BoldOblique", 24)
    c.setFillColorRGB(0, 0, 0)
    c.drawCentredString(w/2, h/2 + 100, "ASK")
    c.setFont("Helvetica-Bold", 18)
    c.drawCentredString(w/2, h/2 + 50, "DAILY ARCHITECTURAL")
    c.setFont("Helvetica-Bold", 18)
    c.drawCentredString(w/2, h/2 + 20, "RESEARCH ZINE")
    c.setFont("Helvetica", 14)
    c.drawCentredString(w/2, h/2 - 20, f"Volume {year}.{day_of_year:03d}")
    c.setFont("Helvetica", 12)
    c.drawCentredString(w/2, h/2 - 50, f"{style_name.capitalize()} Edition")
    c.setFont("Helvetica", 10)
    c.drawCentredString(w/2, h/2 - 80, f"Theme: {theme}")
    c.setFont("Helvetica", 8)
    c.drawCentredString(w/2, h/2 - 120, "50 Full-Bleed Architectural Images")
    c.drawCentredString(w/2, h/2 - 140, "Architectural Research & Poetry")
    c.drawCentredString(w/2, h/2 - 160, "Daily Collection of Architectural Vision")
    c.showPage()
    page_count += 1
    
    c.save()
    
    log.info(f"üéâ Daily PDF created successfully!")
    log.info(f"üìÅ File: {pdf_path}")
    log.info(f"üìÑ Pages: {page_count}")
    log.info(f"üìè Size: {os.path.getsize(pdf_path)} bytes")
    
    return pdf_path

# === üöÄ Main Function ===
def main():
    """Main function to run the daily zine generation with Free Tier Optimized settings"""
    
    # Parse command line arguments
    parser = argparse.ArgumentParser(description='Daily Zine Generator - Free Tier Optimized')
    parser.add_argument('--test', action='store_true', help='Run in test mode with fewer images')
    parser.add_argument('--debug', action='store_true', help='Enable debug logging')
    parser.add_argument('--images', type=int, default=50, help='Number of images to generate (default: 50)')
    parser.add_argument('--style', type=str, help='Force specific style (e.g., technical, abstract)')
    parser.add_argument('--theme', type=str, help='Force specific theme instead of web scraping')
    parser.add_argument('--sources', action='store_true', help='Display current architectural sources')
    parser.add_argument('--fast', action='store_true', help='Enable fast mode (Free Tier Optimized)')
    parser.add_argument('--ultra', action='store_true', help='Enable ultra mode (Conservative Free Tier Optimization)')
    
    args = parser.parse_args()
    
    # Set debug level if requested
    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Override settings for fast mode (Free Tier Optimized)
    if args.fast:
        global FAST_MODE, SKIP_CAPTION_DEDUPLICATION, RATE_LIMIT_DELAY
        FAST_MODE = True
        SKIP_CAPTION_DEDUPLICATION = True
        RATE_LIMIT_DELAY = float(get_env('ULTRA_MODE_DELAY', '0.4'))  # Configurable for faster but still safe operation
    
    # Override settings for ultra mode (Free Tier Optimized - Conservative)
    if args.ultra:
        global FAST_MODE, SKIP_CAPTION_DEDUPLICATION, RATE_LIMIT_DELAY, MAX_CONCURRENT_IMAGES, MAX_CONCURRENT_CAPTIONS
        FAST_MODE = True
        SKIP_CAPTION_DEDUPLICATION = True
        RATE_LIMIT_DELAY = float(get_env('ULTRA_MODE_DELAY', '0.4'))  # Configurable - conservative for free tier safety
        MAX_CONCURRENT_IMAGES = int(get_env('ULTRA_MODE_CONCURRENT_IMAGES', '10'))  # Configurable conservative increase
        MAX_CONCURRENT_CAPTIONS = int(get_env('ULTRA_MODE_CONCURRENT_CAPTIONS', '10'))  # Configurable conservative increase
    
    # Handle sources display
    if args.sources:
        log.info("üìä Displaying architectural sources...")
        display_architectural_sources()
        return
    
    log.info("üöÄ Starting Daily Zine Generator - Free Tier Optimized")
    log.info(f"‚ö° Fast Mode: {FAST_MODE}")
    log.info(f"üé® Concurrent Images: {MAX_CONCURRENT_IMAGES}")
    log.info(f"üìù Concurrent Captions: {MAX_CONCURRENT_CAPTIONS}")
    log.info(f"‚è±Ô∏è Rate Limit Delay: {RATE_LIMIT_DELAY}s")
    log.info(f"üö´ Skip Caption Deduplication: {SKIP_CAPTION_DEDUPLICATION}")
    log.info("üìã Pipeline: Web Scraping ‚Üí Style Selection ‚Üí Prompt Generation ‚Üí Image Generation ‚Üí Caption Generation ‚Üí PDF Creation")
    log.info("üí∞ Free Tier Limit: ~100 requests/minute - Conservative optimization for Together.ai free tier")
    
    # Start timing
    start_time = time.time()
    
    # Overall pipeline progress bar
    with tqdm(total=6, desc=f"üöÄ Overall Pipeline Progress", unit="step", 
              bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pipeline_pbar:
        
        # Step 1: Scrape web for architectural content or use provided theme
        log.info("=" * 60)
        log.info("üì° STEP 1/6: Scraping web for architectural content")
        log.info("=" * 60)
        pipeline_pbar.set_description(f"üì° Step 1/6: Web Scraping")
        
        if args.theme:
            theme = args.theme
            log.info(f"üéØ Using provided theme: {theme}")
        else:
            theme = scrape_architectural_content()
            log.info(f"üéØ Theme selected: {theme}")
        
        pipeline_pbar.set_postfix_str(f"‚úÖ Theme: {theme[:30]}...")
        pipeline_pbar.update(1)
        if not FAST_MODE:
            time.sleep(2)  # Rate limiting between major steps
        
        # Step 2: Select daily style
        log.info("=" * 60)
        log.info("üé® STEP 2/6: Selecting daily style")
        log.info("=" * 60)
        pipeline_pbar.set_description(f"üé® Step 2/6: Style Selection")
        
        if args.style:
            style_name = args.style.lower()
            log.info(f"üéØ Using provided style: {style_name.upper()}")
        else:
            style_name = get_daily_style()
            log.info(f"üéØ Selected style: {style_name.upper()}")
        
        pipeline_pbar.set_postfix_str(f"‚úÖ Style: {style_name.upper()}")
        pipeline_pbar.update(1)
        if not FAST_MODE:
            time.sleep(2)  # Rate limiting between major steps
        
        # Step 3: Generate prompts
        test_count = int(get_env('TEST_IMAGE_COUNT', '5'))
        num_prompts = test_count if args.test else args.images
        log.info("=" * 60)
        log.info(f"‚úçÔ∏è STEP 3/6: Generating {num_prompts} prompts")
        log.info("=" * 60)
        pipeline_pbar.set_description(f"‚úçÔ∏è Step 3/6: Prompt Generation")
        prompts = generate_prompts(theme, num_prompts)
        if not prompts:
            log.error("‚ùå Failed to generate prompts")
            return
        log.info(f"‚úÖ Generated {len(prompts)} prompts")
        pipeline_pbar.set_postfix_str(f"‚úÖ {len(prompts)} prompts")
        pipeline_pbar.update(1)
        if not FAST_MODE:
            time.sleep(2)  # Rate limiting between major steps
        
        # Step 4: Generate images in one style (sequential)
        log.info("=" * 60)
        log.info(f"üñºÔ∏è STEP 4/6: Generating {len(prompts)} images sequentially")
        log.info("=" * 60)
        pipeline_pbar.set_description(f"üñºÔ∏è Step 4/6: Image Generation")
        images = generate_all_images(prompts, style_name)
        if not images:
            log.error("‚ùå Failed to generate images")
            return
        log.info(f"‚úÖ Generated {len(images)} images")
        pipeline_pbar.set_postfix_str(f"‚úÖ {len(images)} images")
        pipeline_pbar.update(1)
        if not FAST_MODE:
            time.sleep(2)  # Rate limiting between major steps
        
        # Step 5: Generate captions (sequential)
        log.info("=" * 60)
        log.info("üìù STEP 5/6: Generating captions sequentially")
        log.info("=" * 60)
        pipeline_pbar.set_description(f"üìù Step 5/6: Caption Generation")
        captions = generate_all_captions(prompts)
        log.info(f"‚úÖ Generated {len(captions)} captions")
        pipeline_pbar.set_postfix_str(f"‚úÖ {len(captions)} captions")
        pipeline_pbar.update(1)
        time.sleep(2)  # Rate limiting between major steps
        
        # Step 6: Create PDF
        log.info("=" * 60)
        log.info("üìÑ STEP 6/6: Creating PDF")
        log.info("=" * 60)
        pipeline_pbar.set_description(f"üìÑ Step 6/6: PDF Creation")
        pdf_path = create_daily_pdf(images, captions, style_name, theme)
        pipeline_pbar.set_postfix_str(f"‚úÖ PDF created")
        pipeline_pbar.update(1)
        
        if pdf_path:
            # Calculate performance metrics
            total_time = time.time() - start_time
            images_per_second = len(images) / total_time if total_time > 0 else 0
            
            log.info("=" * 60)
            log.info("üéâ 10X SPEED OPTIMIZED PIPELINE COMPLETED SUCCESSFULLY!")
            log.info("=" * 60)
            log.info(f"üìÅ PDF: {pdf_path}")
            log.info(f"üé® Style: {style_name.upper()}")
            log.info(f"üìä Images: {len(images)}")
            log.info(f"üìù Captions: {len(captions)}")
            log.info(f"üéØ Theme: {theme}")
            log.info(f"‚ö° Total Time: {total_time:.2f} seconds")
            log.info(f"üöÄ Performance: {images_per_second:.2f} images/second")
            log.info(f"üéØ Speed Improvement: ~10x faster than sequential mode")
            log.info("‚úÖ All steps completed with concurrent processing!")
        else:
            log.error("‚ùå Failed to create daily PDF")

if __name__ == "__main__":
    main() 